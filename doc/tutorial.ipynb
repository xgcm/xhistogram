{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xhistogram Tutorial\n",
    "\n",
    "Histograms are the foundation of many forms of data analysis.\n",
    "The goal of xhistogram is to make it easy to calculate weighted histograms in multiple dimensions over n-dimensional arrays, with control over the axes.\n",
    "Xhistogram builds on top of xarray, for automatic coordiantes and labels, and dask, for parallel scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Data\n",
    "\n",
    "We start by showing an example with toy data. First we use xarray to create some random, normally distributed data.\n",
    "\n",
    "### 1D Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "nt, nx = 100, 30\n",
    "da = xr.DataArray(np.random.randn(nt, nx), dims=['time', 'x'])\n",
    "display(da)\n",
    "da.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default xhistogram operates on all dimensions of an array, just like numpy. However, it operates on xarray DataArrays, taking labels into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xhistogram.xarray import histogram\n",
    "\n",
    "bins = np.linspace(-4, 4, 20)\n",
    "h = histogram(da, bins=[bins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error occurred because no name was given to `da` (e.g. `da.name == None`) and `histogram` needs that to determine the name of the output dimension.\n",
    "We can solve this by either renaming `da` at the `histogram` input as\n",
    "\n",
    "```python\n",
    "h = histogram(da.rename(\"foo\"), bins=[bins])\n",
    "```\n",
    "\n",
    "or redefining `da` by giving the name at the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da = xr.DataArray(np.random.randn(nt, nx), dims=['time', 'x'], name = \"foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the histogram and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = histogram(da, bins=[bins])\n",
    "display(h)\n",
    "h.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** \n",
    "- Bins needs to be a list; this is annoying, would be good to accept single items\n",
    "- The `foo_bin` coordinate is the estimated bin center, not the bounds. We need to add the bounds to the coordinates, but we can as long as we are returning DataArray and not Dataset.\n",
    "\n",
    "Both of the above need GitHub Issues\n",
    "\n",
    "### Histogram over a single axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_x = histogram(da, bins=[bins], dim=['time'])\n",
    "h_x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "  - Relax / explain requirement that dims is always a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_x.mean(dim='x').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Histogram\n",
    "\n",
    "Weights can be the same shape as the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = 0.4 * xr.ones_like(da)\n",
    "histogram(da, bins=[bins], weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or can use Xarray broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = 0.2 * xr.ones_like(da.x)\n",
    "histogram(da, bins=[bins], weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Histogram\n",
    "\n",
    "Now let's say we have multiple input arrays. We can calculate their joint distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = xr.DataArray(np.random.randn(nt, nx), dims=['time', 'x'],\n",
    "                  name='bar') - 2\n",
    "\n",
    "histogram(da, db, bins=[bins, bins]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data Example\n",
    "\n",
    "### Ocean Volume Census in TS Space\n",
    "\n",
    "Here we show how to use xhistogram to do a volume census of the ocean in Temperature-Salinity Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we open the World Ocean Atlas dataset from the opendap dataset (http://apdrc.soest.hawaii.edu/dods/public_data/WOA/WOA13/1_deg/annual). \n",
    "\n",
    "Here we read the annual mean Temparature, Salinity and Oxygen on a 5 degree grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read WOA using opendap \n",
    "Temp_url = 'http://apdrc.soest.hawaii.edu:80/dods/public_data/WOA/WOA13/5_deg/annual/temp'\n",
    "Salt_url = 'http://apdrc.soest.hawaii.edu:80/dods/public_data/WOA/WOA13/5_deg/annual/salt'\n",
    "Oxy_url = 'http://apdrc.soest.hawaii.edu:80/dods/public_data/WOA/WOA13/5_deg/annual/doxy'\n",
    "\n",
    "ds = xr.merge([\n",
    "    xr.open_dataset(Temp_url).tmn.load(),\n",
    "    xr.open_dataset(Salt_url).smn.load(),\n",
    "    xr.open_dataset(Oxy_url).omn.load()])\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use histogram to bin data points. Use canonical ocean T/S ranges, and bin size of $0.1^0C$, and $0.025psu$. Similar ranges and bin size as this review paper on Mode Waters: https://doi.org/10.1016/B978-0-12-391851-2.00009-X ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbins = np.arange(31,38, 0.025)\n",
    "tbins = np.arange(-2, 32, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# histogram of number of data points\n",
    "# histogram of number of data points\n",
    "hTS = histogram(ds.smn, ds.tmn, bins=[sbins, tbins])\n",
    "np.log10(hTS.T).plot(levels=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we would like to do a volume census, which requires the data points to be weighted by volume of the grid box. \n",
    "\n",
    "\\begin{equation}\n",
    "dV = dz*dx*dy\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# histogram of number of data points weighted by volume resolution\n",
    "# Note that depth is a non-uniform axis\n",
    "\n",
    "# Create a dz variable\n",
    "dz = np.diff(ds.lev)\n",
    "dz = np.insert(dz, 0, dz[0])\n",
    "dz = xr.DataArray(dz, coords= {'lev':ds.lev}, dims='lev')\n",
    "\n",
    "# weight by volume of grid cell (resolution = 5degree, 1degree=110km)\n",
    "dVol = dz * (5*110e3) * (5*110e3*np.cos(ds.lat*np.pi/180)) \n",
    "\n",
    "# Note: The weights are automatically broadcast to the right size\n",
    "hTSw = histogram(ds.smn, ds.tmn, bins=[sbins, tbins], weights=dVol)\n",
    "np.log10(hTSw.T).plot(levels=31, vmin=11.5, vmax=16, cmap='brg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridges of this above plot are indicative of T/S classes with a lot of volume, and some of them are indicative of Mode Waters (example Eighteen Degree water with T$\\sim18^oC$, and S$\\sim36.5psu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's suppose that we have a mask for different regions in the planet. For the sake of simplicity, we will create a mask to separate the globe into three regions.\n",
    "\n",
    "- Tropical: `np.abs(latitude) <= 30`\n",
    "- Temperate: `30 < np.abs(latitude) <= 60`\n",
    "- Polar: `60 < np.abs(latitude)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones = np.abs(ds.lat / 30).round().rename(\"zones\")\n",
    "display(zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are two ways of doing that, we can create a new dimension on the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zonebins = np.arange(-0.5, 4, 1)\n",
    "hTSw = histogram(ds.smn, ds.tmn, zones, bins=[sbins, tbins, zonebins], weights=dVol)\n",
    "np.log10(hTSw.T).plot(levels=31, vmin=11.5, vmax=16, cmap='brg', col = \"zones_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use groupby function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hTSw = ds.assign(dVol = dVol).groupby(zones).apply(lambda ds: histogram(ds.smn, ds.tmn, bins=[sbins, tbins], weights=ds.dVol))\n",
    "np.log10(hTSw.T).plot(levels=31, vmin=11.5, vmax=16, cmap='brg', col = \"zones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second option is more verbose, but more efficient and also works with text or mask values that does not vary monotonically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging a variable \n",
    "\n",
    "Next we calculate the mean oxygen value in each TS bin. \n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{A} (m,n) = \\frac{\\sum_{T(x,y,z)=m, S(x,y,z)=n} (A(x,y,z) dV)}{\\sum_{T(x,y,z)=m, S(x,y,z)=n}dV}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hTSO2 = (histogram(ds.smn.where(~np.isnan(ds.omn)), \n",
    "                   ds.tmn.where(~np.isnan(ds.omn)), \n",
    "                   bins=[sbins, tbins], \n",
    "                   weights=ds.omn.where(~np.isnan(ds.omn))*dVol)/\n",
    "                histogram(ds.smn.where(~np.isnan(ds.omn)), \n",
    "                          ds.tmn.where(~np.isnan(ds.omn)), \n",
    "                          bins=[sbins, tbins], \n",
    "                          weights=dVol))\n",
    "\n",
    "(hTSO2.T).plot(vmin=1, vmax=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting patterns in average oxygen emerge. Convectively ventilated cold water have the highest oxygen and mode waters have relatively high oxygen. Oxygen minimum zones are interspersed in the middle of volumetic ridges (high volume waters). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: NaNs in weights will make the weighted sum as nan. To avoid this, call `.fillna(0.)` on your weights input data before calling `histogram()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Integration\n",
    "\n",
    "Should just work, but need examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coringa0.3.0",
   "language": "python",
   "name": "coringa0.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
